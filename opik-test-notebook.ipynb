{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "045051a3",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4469805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opik.evaluation.metrics.score_result import ScoreResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2f8cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in our code bleu score is actually cosine similarity which uses this class and function I GUESS\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import re, math\n",
    "class Comparator(ABC):\n",
    "    @abstractmethod\n",
    "    def compare(self, string1, string2):\n",
    "        pass\n",
    "\n",
    "class CosineSimilarity(Comparator):\n",
    "    def compare(self, string1, string2):\n",
    "        # Tokenize and create a combined set of unique words\n",
    "        combined_set = self._create_combined_set(string1, string2)\n",
    "        # Vectorize the strings\n",
    "        vector1 = self._vectorize(string1, combined_set)\n",
    "        vector2 = self._vectorize(string2, combined_set)\n",
    "        dot_product = sum(p*q for p, q in zip(vector1, vector2))\n",
    "        magnitude_vec1 = math.sqrt(sum([val**2 for val in vector1]))\n",
    "        magnitude_vec2 = math.sqrt(sum([val**2 for val in vector2]))\n",
    "        if magnitude_vec1 * magnitude_vec2 == 0:\n",
    "            # Avoid division by zero\n",
    "            return 0\n",
    "        return dot_product / (magnitude_vec1 * magnitude_vec2)\n",
    "\n",
    "    def _tokenize(self, string):\n",
    "        \"\"\"\n",
    "        Tokenize the input string into a list of words.\n",
    "        \n",
    "        Args:\n",
    "            string (str): The string to tokenize.\n",
    "        \n",
    "        Returns:\n",
    "            list: A list of lowercased words from the string.\n",
    "        \"\"\"\n",
    "        return re.findall(r'\\b\\w+\\b', string.lower())\n",
    "\n",
    "    def _create_combined_set(self, string1, string2):\n",
    "        return set(self._tokenize(string1)).union(set(self._tokenize(string2)))\n",
    "\n",
    "    def _vectorize(self, string, combined_set):\n",
    "        tokenized = self._tokenize(string)\n",
    "        vector = [tokenized.count(word) for word in combined_set]\n",
    "        return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "727150ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opik expects the SAME keywords for the metric function else it throws an unknown error that doesnt even tell u the problem is with keywords. \n",
    "def cosine_score(dataset_item, llm_output):\n",
    "    score = CosineSimilarity().compare(dataset_item.get('answer'), llm_output)\n",
    "    return ScoreResult(name=\"CosineSimilarity\", value=score, reason=f\"Cosine similarity was found to be {score}\", scoring_failed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c34eaffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdc274a",
   "metadata": {},
   "source": [
    "## Create Dataset and Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55b32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opik_optimizer import ChatPrompt\n",
    "from opik import Opik\n",
    "import pandas as pd\n",
    "\n",
    "# generated answer is the column which uses the prompt 'given {{context}}, answer the {{question}}' \n",
    "# answer similarity uses bleu score betweeen generated answer and the answer\n",
    "data = pd.read_csv('demo-dataset.csv')[['context','question','answer','generated answer', 'Answer Similarity', 'Groundedness']]\n",
    "\n",
    "cli= Opik(project_name='fi')\n",
    "\n",
    "dataset = cli.get_or_create_dataset(name='prompt-opt-test')\n",
    "dataset.insert_from_pandas(dataframe=data)\n",
    "\n",
    "initial_prompt = ChatPrompt(\n",
    "    name = 'init-qa-prompt',\n",
    "    user='given {context}, answer the {question}',\n",
    "    project_name=\"fi\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c55fc19",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098fee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opik_optimizer import MetaPromptOptimizer, EvolutionaryOptimizer, FewShotBayesianOptimizer\n",
    "from opik_optimizer.mipro_optimizer import MiproOptimizer\n",
    "\n",
    "common_opt_params = {\n",
    "    \"model\":'openai/gpt-4o-mini',\n",
    "    \"temperature\":0.5,\n",
    "    \"verbose\":1,\n",
    "    \"n_threads\":5,\n",
    "    \"max_tokens\":1024,\n",
    "    # \"seed\":47\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abd0d9c",
   "metadata": {},
   "source": [
    "## Meta Prompt Optimizer\n",
    "mainly used for re-wording the prompt, and not really recommended for complex tasks like agentic or prompts with few shot examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d93a1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_optimizer = MetaPromptOptimizer(\n",
    "    **common_opt_params,\n",
    "    reasoning_model='openai/gpt-4o',\n",
    "    max_rounds = 3,\n",
    "    num_prompts_per_round=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8feeb7",
   "metadata": {},
   "source": [
    "## Evolutionary Optimizer\n",
    "main usecase is optimizing for complex evaluations, or group of evaluations. It uses much higher number of mutations to explore as many prompt combinations as possible.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f84230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evo_optimizer = EvolutionaryOptimizer(\n",
    "    **common_opt_params,\n",
    "    population_size=3,                 # Number of prompts in each generation\n",
    "    num_generations=2,                 # Number of iterations the algorithm will run\n",
    "    mutation_rate=0.2,                  # Probability of mutating an individual\n",
    "    crossover_rate=0.8,                 # Probability of crossing over two individuals\n",
    "    tournament_size=4,                  # Size of the tournament for selection (if not MOO)\n",
    "    elitism_size=3,                     # Number of best individuals to carry over (if not MOO)\n",
    "    adaptive_mutation=True,\n",
    "    enable_llm_crossover=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2a85c8",
   "metadata": {},
   "source": [
    "## FewShot Bayesian Optimizer\n",
    "used when prompts should contain fewshot examples. can burn through tokens very easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb86328",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_optimizer = FewShotBayesianOptimizer(\n",
    "    **common_opt_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f0d0f",
   "metadata": {},
   "source": [
    "## MIPRO Optimizer\n",
    "main use case is complex multi step reasoning or tool use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b50d8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "mipro_optimizer = MiproOptimizer(\n",
    "    model = common_opt_params['model'],\n",
    "    project_name=\"fi\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ab98c",
   "metadata": {},
   "source": [
    "## Final Optimize Prompt Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f693165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_opt_run_params = {\n",
    "    \"prompt\": initial_prompt,\n",
    "    \"dataset\": dataset,\n",
    "    \"metric\": cosine_score,\n",
    "    \"n_samples\": 7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84d41759",
   "metadata": {},
   "outputs": [],
   "source": [
    "optims = [meta_optimizer, evo_optimizer]\n",
    "# evo takes much much much longer to optimize. Really not recommended tbh. Should run separately.\n",
    "# bayes results in hallucinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "989f51ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing using MetaPromptOptimizer\n",
      "╭────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[32m● \u001b[0mRunning Opik Evaluation - \u001b[34mMetaPromptOptimizer\u001b[0m                    │\n",
      "│                                                                    │\n",
      "│ -> View optimization details \u001b]8;id=26225;https://www.comet.com/opik/api/v1/session/redirect/optimizations/?optimization_id=01997687-fd45-7ff1-8199-e297d5bf6b5f&dataset_id=01997609-de6f-707e-ba5c-3c7756e0eb62&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\u001b\\in your Opik dashboard\u001b]8;;\u001b\\                │\n",
      "╰────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "\n",
      "> Let's optimize the prompt:\n",
      "\n",
      "\u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\n",
      "Using MetaPromptOptimizer with the parameters: \n",
      "\u001b[2m  - n_samples: \u001b[0m\u001b[36m7\u001b[0m\n",
      "\u001b[2m  - auto_continue: \u001b[0m\u001b[36mFalse\u001b[0m\n",
      "\n",
      "\n",
      "> First we will establish the baseline performance:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856b6a9a12e341e18f760a139a7c3f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m  Baseline score was: 0.7537.\u001b[0m\n",
      "\n",
      "> Starting the optimization run\n",
      "│\n",
      "│ - Starting optimization round 1 of 3\n",
      "│    Generating candidate prompts:\n",
      "\u001b[2m│      Successfully generated 3 candidate prompts\u001b[0m\n",
      "│\n",
      "│    Evaluating candidate prompt 1:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  Using the provided {context}, answer the {question} as            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  accurately as possible. Ensure your response is concise and       \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  directly addresses the question, reflecting the key points from   \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  the context.                                                      \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207b16a0d400489ab1d56e76786b681d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m│          Evaluation score: 0.8394 (11.37%)\u001b[0m\n",
      "│\n",
      "│\n",
      "│    Evaluating candidate prompt 2:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  Refer to the {context} to provide a precise answer to the         \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  {question}. Your response should be a well-structured sentence    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  that captures the essence of the context related to the           \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  question.                                                         \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b98b86828b74f60b887ef0eb2896d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m│          Evaluation score: 0.7661 (1.65%)\u001b[0m\n",
      "│\n",
      "│\n",
      "│    Evaluating candidate prompt 3:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  Based on the {context}, generate an answer to the {question}      \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  that highlights the main goal or purpose mentioned. Ensure your   \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  answer is succinct and aligns with the context provided.          \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbeb301da7d74644addad2469547ba3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m│          Evaluation score: 0.7532 (-0.07%)\u001b[0m\n",
      "│\n",
      "│\n",
      "│    Completed optimization round 1 of 3\n",
      "\u001b[32m│    Found a new best performing prompt: 0.8394 (11.37%)\u001b[0m\n",
      "│\n",
      "│ - Starting optimization round 2 of 3\n",
      "│    Generating candidate prompts:\n",
      "\u001b[2m│      Successfully generated 3 candidate prompts\u001b[0m\n",
      "│\n",
      "│    Evaluating candidate prompt 1:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  Utilize the given {context} to provide a precise and concise      \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  answer to the {question}. Ensure your response directly reflects  \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  the main points from the context and addresses the question       \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  accurately.                                                       \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae35213bdf8841ad8a09690e578ed64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m│          Evaluation score: 0.7531 (-10.28%)\u001b[0m\n",
      "│\n",
      "│\n",
      "│    Evaluating candidate prompt 2:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  From the provided {context}, extract and summarize the key        \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  information needed to answer the {question}. Your response        \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  should be concise and directly related to the question.           \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fc3f3757ae4f2eb1c9df61fa6180a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m│          Evaluation score: 0.7854 (-6.43%)\u001b[0m\n",
      "│\n",
      "│\n",
      "│    Evaluating candidate prompt 3:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  Refer to the {context} to construct a clear and concise answer    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  to the {question}. Ensure your response highlights the core       \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  elements from the context that are essential for addressing the   \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  question.                                                         \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc18b299cc74b11b0b74cd0f0cf617e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m│          Evaluation score: 0.7089 (-15.55%)\u001b[0m\n",
      "│\n",
      "│\n",
      "│    Completed optimization round 2 of 3\n",
      "\u001b[31m│    No improvement in this optimization round\u001b[0m\n",
      "│\n",
      "│ - Starting optimization round 3 of 3\n",
      "│    Generating candidate prompts:\n",
      "\u001b[2m│      Successfully generated 3 candidate prompts\u001b[0m\n",
      "│\n",
      "│    Evaluating candidate prompt 1:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  Using the provided {context}, generate a concise and precise      \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  answer to the {question}. Focus on extracting key points from     \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  the context that directly address the question. Ensure your       \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  response is well-structured and reflects the main ideas           \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  accurately.                                                       \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb43ccfa54cd418d9f177e82c1dd7d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m│          Evaluation score: 0.7263 (-13.47%)\u001b[0m\n",
      "│\n",
      "│\n",
      "│    Evaluating candidate prompt 2:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  From the given {context}, derive a direct and succinct answer to  \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  the {question}. Highlight the essential elements that are         \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  crucial for addressing the question. Your response should be      \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  clear and reflect the core message of the context.                \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcff28a607e84cfa939f872f026ec575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m│          Evaluation score: 0.6867 (-18.18%)\u001b[0m\n",
      "│\n",
      "│\n",
      "│    Evaluating candidate prompt 3:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  Utilize the provided {context} to construct a concise answer to   \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  the {question}. Ensure your response captures the main points     \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  from the context that are necessary to accurately address the     \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  question. The answer should be structured and directly relevant.  \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ec8cecc87c4852ae4df6036fe13b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m│          Evaluation score: 0.7316 (-12.84%)\u001b[0m\n",
      "│\n",
      "│\n",
      "│    Completed optimization round 3 of 3\n",
      "\u001b[31m│    No improvement in this optimization round\u001b[0m\n",
      "│\n",
      "\n",
      "> Optimization complete\n",
      "\n",
      "\u001b[32m╭─\u001b[0m\u001b[32m Optimization results \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
      "\u001b[32m│\u001b[0m                                                                    \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[1;32mPrompt was optimized and improved from 0.7537 to 0.8394 (11.37%)\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m                                                                    \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  Optimized prompt:                                                 \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m│\u001b[0m                                                              \u001b[2m│\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m│\u001b[0m  Using the provided {context}, answer the {question} as      \u001b[2m│\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m│\u001b[0m  accurately as possible. Ensure your response is concise     \u001b[2m│\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m│\u001b[0m  and directly addresses the question, reflecting the key     \u001b[2m│\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m│\u001b[0m  points from the context.                                    \u001b[2m│\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m│\u001b[0m                                                              \u001b[2m│\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m╰──────────────────────────────────────────────────────────────╯\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m──────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m│\u001b[0m                                                              \u001b[2m│\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m│\u001b[0m  given {context}, answer the {question}                      \u001b[2m│\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m│\u001b[0m                                                              \u001b[2m│\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m╰──────────────────────────────────────────────────────────────╯\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m                                                                    \u001b[32m│\u001b[0m\n",
      "\u001b[32m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "Optimizing using EvolutionaryOptimizer\n",
      "╭────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[32m● \u001b[0mRunning Opik Evaluation - \u001b[34mEvolutionaryOptimizer\u001b[0m                  │\n",
      "│                                                                    │\n",
      "│ -> View optimization details \u001b]8;id=256787;https://www.comet.com/opik/api/v1/session/redirect/optimizations/?optimization_id=0199768a-6a5a-7493-88f4-120ca91341f6&dataset_id=01997609-de6f-707e-ba5c-3c7756e0eb62&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\u001b\\in your Opik dashboard\u001b]8;;\u001b\\                │\n",
      "╰────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "\n",
      "> Let's optimize the prompt:\n",
      "\n",
      "\u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\n",
      "Using DEAP MOO Evolutionary Optimization with the parameters: \n",
      "\u001b[2m  - population_size: \u001b[0m\u001b[36m3\u001b[0m\n",
      "\u001b[2m  - generations: \u001b[0m\u001b[36m2\u001b[0m\n",
      "\u001b[2m  - mutation_rate: \u001b[0m\u001b[36m0.2\u001b[0m\n",
      "\u001b[2m  - crossover_rate: \u001b[0m\u001b[36m0.8\u001b[0m\n",
      "\n",
      "\n",
      "> First we will establish the baseline performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7189c8c48c5c49b5bede95bd83260b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m  Baseline score was: 0.7537.\u001b[0m\n",
      "\n",
      "> Creating \u001b[1;36m2\u001b[0m variations of the initial prompt\n",
      "│\n",
      "│    Generating \u001b[1;36m1\u001b[0m fresh prompts based on the task description.\n",
      "│       \u001b[2;32mSuccessfully generated 1 fresh prompts based on the task description.\u001b[0m\n",
      "│\n",
      "│    Generating \u001b[1;36m1\u001b[0m variations of the initial prompt.\n",
      "\u001b[2;32m│       Successfully generated 0 variations of the initial prompt).\u001b[0m\n",
      "│\n",
      "│ Successfully initialized population with \u001b[1;36m3\u001b[0m prompts.\n",
      "\n",
      "> Let's now evaluate the initial population\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b6e7c3f34842fdb0dc3a394fe616a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ae55af62f64b30b90b9d786e1cb6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28614ff7fca4f828d0d661e3ef30000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m  Prompt 1 score was: 0.7536625117758369.\u001b[0m\n",
      "\u001b[2m  Prompt 2 score was: 0.6211151415243.\u001b[0m\n",
      "\u001b[2m  Prompt 3 score was: 0.6546858447019043.\u001b[0m\n",
      "\n",
      "> Starting evolutionary algorithm optimization\n",
      "│   Starting generation 1 of 2\n",
      "│      Performing crossover - Combining multiple prompts into a new one.\n",
      "│   \u001b[2m      Recombining prompts using an LLM.\u001b[0m\n",
      "│   \u001b[2;32m      Crossover successful, prompts have been combined and edited.\u001b[0m\n",
      "\u001b[2;32m│\u001b[0m\n",
      "│      Performing mutation - Altering prompts to improve their performance.\n",
      "│   \u001b[2;32m      Mutation successful, 0 prompts have been edited.\u001b[0m\n",
      "\u001b[2;32m│\u001b[0m\n",
      "│      Performing evaluation - Assessing 2 prompts' performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed6d550e73441f89eadae504d4dc2d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m│      Performed evaluation for prompt 0 - Score: 0.6007.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c8de749882491fbdd24c41a432d81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m│      Performed evaluation for prompt 1 - Score: 0.6002.\u001b[0m\n",
      "│   Generation 1 completed. No improvement in this generation.\n",
      "│\n",
      "│   Starting generation 2 of 2\n",
      "│      Performing crossover - Combining multiple prompts into a new one.\n",
      "│   \u001b[2m      Recombining prompts using an LLM.\u001b[0m\n",
      "│   \u001b[2;32m      Crossover successful, prompts have been combined and edited.\u001b[0m\n",
      "\u001b[2;32m│\u001b[0m\n",
      "│      Performing mutation - Altering prompts to improve their performance.\n",
      "│   \u001b[2;32m      Mutation successful, prompt has been edited using an LLM (semantic mutation).\u001b[0m\n",
      "│   \u001b[2;32m      Mutation successful, 1 prompts have been edited.\u001b[0m\n",
      "\u001b[2;32m│\u001b[0m\n",
      "│      Performing evaluation - Assessing 2 prompts' performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99aff4fb515d4c28aa2ad471a22ebc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m│      Performed evaluation for prompt 0 - Score: 0.6353.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e435c4d66d8747868536dd9198232a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m│      Performed evaluation for prompt 1 - Score: 0.7033.\u001b[0m\n",
      "│   Generation 2 completed. No improvement in this generation.\n",
      "│\n",
      "\n",
      "\n",
      "> Optimization complete\n",
      "\n",
      "\u001b[32m╭─\u001b[0m\u001b[32m Optimization results \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
      "\u001b[32m│\u001b[0m                                                                    \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[1;2;31mOptimization run did not find a better prompt than the initial \u001b[0m   \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[1;2;31mone.\u001b[0m                                                              \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[1;2;31mScore: 0.7537\u001b[0m                                                     \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m                                                                    \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  Optimized prompt:                                                 \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m──────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m│\u001b[0m                                                              \u001b[2m│\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m│\u001b[0m  given {context}, answer the {question}                      \u001b[2m│\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m│\u001b[0m                                                              \u001b[2m│\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m  \u001b[2m╰──────────────────────────────────────────────────────────────╯\u001b[0m  \u001b[32m│\u001b[0m\n",
      "\u001b[32m│\u001b[0m                                                                    \u001b[32m│\u001b[0m\n",
      "\u001b[32m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from opik_optimizer import TaskConfig\n",
    "\n",
    "results = []\n",
    "\n",
    "for optim in optims:\n",
    "    print(f\"Optimizing using {optim.__class__.__name__}\")\n",
    "\n",
    "    if isinstance(optim, MiproOptimizer):\n",
    "        res = optim.optimize_prompt(\n",
    "            dataset=dataset,\n",
    "            metric=cosine_score,\n",
    "            task_config = TaskConfig(\n",
    "                instruction_prompt = common_opt_run_params['prompt'].user,\n",
    "                input_dataset_fields = ['question','context'],\n",
    "                output_dataset_field = 'answer',\n",
    "                use_chat_prompt = True\n",
    "            ),\n",
    "            num_candidates=1,\n",
    "        )\n",
    "    else:\n",
    "        res = optim.optimize_prompt(\n",
    "            **common_opt_run_params\n",
    "        )\n",
    "    results.append(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-opts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

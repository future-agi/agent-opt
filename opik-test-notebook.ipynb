{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "045051a3",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4469805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opik.evaluation.metrics.score_result import ScoreResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2f8cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in our code bleu score is actually cosine similarity which uses this class and function I GUESS\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import re, math\n",
    "class Comparator(ABC):\n",
    "    @abstractmethod\n",
    "    def compare(self, string1, string2):\n",
    "        pass\n",
    "\n",
    "class CosineSimilarity(Comparator):\n",
    "    def compare(self, string1, string2):\n",
    "        # Tokenize and create a combined set of unique words\n",
    "        combined_set = self._create_combined_set(string1, string2)\n",
    "        # Vectorize the strings\n",
    "        vector1 = self._vectorize(string1, combined_set)\n",
    "        vector2 = self._vectorize(string2, combined_set)\n",
    "        dot_product = sum(p*q for p, q in zip(vector1, vector2))\n",
    "        magnitude_vec1 = math.sqrt(sum([val**2 for val in vector1]))\n",
    "        magnitude_vec2 = math.sqrt(sum([val**2 for val in vector2]))\n",
    "        if magnitude_vec1 * magnitude_vec2 == 0:\n",
    "            # Avoid division by zero\n",
    "            return 0\n",
    "        return dot_product / (magnitude_vec1 * magnitude_vec2)\n",
    "\n",
    "    def _tokenize(self, string):\n",
    "        \"\"\"\n",
    "        Tokenize the input string into a list of words.\n",
    "        \n",
    "        Args:\n",
    "            string (str): The string to tokenize.\n",
    "        \n",
    "        Returns:\n",
    "            list: A list of lowercased words from the string.\n",
    "        \"\"\"\n",
    "        return re.findall(r'\\b\\w+\\b', string.lower())\n",
    "\n",
    "    def _create_combined_set(self, string1, string2):\n",
    "        return set(self._tokenize(string1)).union(set(self._tokenize(string2)))\n",
    "\n",
    "    def _vectorize(self, string, combined_set):\n",
    "        tokenized = self._tokenize(string)\n",
    "        vector = [tokenized.count(word) for word in combined_set]\n",
    "        return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "727150ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opik expects the SAME keywords for the metric function else it throws an unknown error that doesnt even tell u the problem is with keywords. \n",
    "def cosine_score(dataset_item, llm_output):\n",
    "    score = CosineSimilarity().compare(dataset_item.get('answer'), llm_output)\n",
    "    return ScoreResult(name=\"CosineSimilarity\", value=score, reason=f\"Cosine similarity was found to be {score}\", scoring_failed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2305c64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/Desktop/agent-opts/.venv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:198: UserWarning: Field name \"json\" in \"RequestConfig\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from fi.evals import Evaluator\n",
    "evaluator = Evaluator()\n",
    "\n",
    "def fi_eval(dataset_item, llm_output):\n",
    "    eval = evaluator.evaluate(\n",
    "        eval_templates=\"context_adherence\",\n",
    "        model_name=\"turing_flash\",\n",
    "        inputs={\n",
    "            \"context\": dataset_item.get(\"context\"),\n",
    "            \"output\": llm_output\n",
    "        }\n",
    "    )\n",
    "    return ScoreResult(name=\"FutureAGI Eval\", value=eval.eval_results[0].output, reason=eval.eval_results[0].reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c34eaffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdc274a",
   "metadata": {},
   "source": [
    "## Create Dataset and Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b55b32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opik_optimizer import ChatPrompt\n",
    "from opik import Opik\n",
    "import pandas as pd\n",
    "\n",
    "# generated answer is the column which uses the prompt 'given {{context}}, answer the {{question}}' \n",
    "# answer similarity uses bleu score betweeen generated answer and the answer\n",
    "data = pd.read_csv('demo-dataset.csv')[['context','question','answer','generated answer', 'Answer Similarity', 'Groundedness']]\n",
    "\n",
    "cli= Opik(project_name='fi')\n",
    "\n",
    "dataset = cli.get_or_create_dataset(name='prompt-opt-test')\n",
    "dataset.insert_from_pandas(dataframe=data)\n",
    "\n",
    "initial_prompt = ChatPrompt(\n",
    "    name = 'init-qa-prompt',\n",
    "    user='given {context}, answer the {question}',\n",
    "    project_name=\"fi\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c55fc19",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "098fee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opik_optimizer import MetaPromptOptimizer, EvolutionaryOptimizer, FewShotBayesianOptimizer\n",
    "from opik_optimizer.mipro_optimizer import MiproOptimizer\n",
    "\n",
    "common_opt_params = {\n",
    "    \"model\":'openai/gpt-4o-mini',\n",
    "    \"temperature\":0.5,\n",
    "    \"verbose\":1,\n",
    "    \"n_threads\":5,\n",
    "    \"max_tokens\":1024,\n",
    "    # \"seed\":47\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abd0d9c",
   "metadata": {},
   "source": [
    "## Meta Prompt Optimizer\n",
    "mainly used for re-wording the prompt, and not really recommended for complex tasks like agentic or prompts with few shot examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d93a1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_optimizer = MetaPromptOptimizer(\n",
    "    **common_opt_params,\n",
    "    reasoning_model='openai/gpt-4o',\n",
    "    max_rounds = 3,\n",
    "    num_prompts_per_round=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8feeb7",
   "metadata": {},
   "source": [
    "## Evolutionary Optimizer\n",
    "main usecase is optimizing for complex evaluations, or group of evaluations. It uses much higher number of mutations to explore as many prompt combinations as possible.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f84230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evo_optimizer = EvolutionaryOptimizer(\n",
    "    **common_opt_params,\n",
    "    population_size=3,                 # Number of prompts in each generation\n",
    "    num_generations=2,                 # Number of iterations the algorithm will run\n",
    "    mutation_rate=0.2,                  # Probability of mutating an individual\n",
    "    crossover_rate=0.8,                 # Probability of crossing over two individuals\n",
    "    tournament_size=4,                  # Size of the tournament for selection (if not MOO)\n",
    "    elitism_size=3,                     # Number of best individuals to carry over (if not MOO)\n",
    "    adaptive_mutation=True,\n",
    "    enable_llm_crossover=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2a85c8",
   "metadata": {},
   "source": [
    "## FewShot Bayesian Optimizer\n",
    "used when prompts should contain fewshot examples. can burn through tokens very easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbb86328",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_optimizer = FewShotBayesianOptimizer(\n",
    "    **common_opt_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f0d0f",
   "metadata": {},
   "source": [
    "## MIPRO Optimizer\n",
    "main use case is complex multi step reasoning or tool use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b50d8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "mipro_optimizer = MiproOptimizer(\n",
    "    model = common_opt_params['model'],\n",
    "    project_name=\"fi\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ab98c",
   "metadata": {},
   "source": [
    "## Final Optimize Prompt Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f693165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_opt_run_params = {\n",
    "    \"prompt\": initial_prompt,\n",
    "    \"dataset\": dataset,\n",
    "    \"metric\": fi_eval,\n",
    "    \"n_samples\": 7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84d41759",
   "metadata": {},
   "outputs": [],
   "source": [
    "optims = [meta_optimizer, evo_optimizer, bayes_optimizer]\n",
    "# evo takes much much much longer to optimize. Really not recommended tbh. Should run separately.\n",
    "# bayes results in hallucinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f51ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing using MetaPromptOptimizer\n",
      "╭────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[32m● \u001b[0mRunning Opik Evaluation - \u001b[34mMetaPromptOptimizer\u001b[0m                    │\n",
      "│                                                                    │\n",
      "│ -> View optimization details \u001b]8;id=26225;https://www.comet.com/opik/api/v1/session/redirect/optimizations/?optimization_id=019976db-87ce-7da4-815a-2d92dd071486&dataset_id=01997609-de6f-707e-ba5c-3c7756e0eb62&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\u001b\\in your Opik dashboard\u001b]8;;\u001b\\                │\n",
      "╰────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "\n",
      "> Let's optimize the prompt:\n",
      "\n",
      "\u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\n",
      "Using MetaPromptOptimizer with the parameters: \n",
      "\u001b[2m  - n_samples: \u001b[0m\u001b[36m7\u001b[0m\n",
      "\u001b[2m  - auto_continue: \u001b[0m\u001b[36mFalse\u001b[0m\n",
      "\n",
      "\n",
      "> First we will establish the baseline performance:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03b356b85cc463794d2cf29e7c8eeae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m  Baseline score was: 0.8286.\u001b[0m\n",
      "\n",
      "> Starting the optimization run\n",
      "│\n",
      "│ - Starting optimization round 1 of 3\n",
      "│    Generating candidate prompts:\n",
      "\u001b[2m│      Successfully generated 3 candidate prompts\u001b[0m\n",
      "│\n",
      "│    Evaluating candidate prompt 1:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  Using the provided {context}, accurately answer the {question}    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  by focusing on the main goal or key information. Ensure your      \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  response is concise and directly related to the question.         \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1430e8b06a5943b8981700b4034e3a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m│          Evaluation score: 0.9143 (10.34%)\u001b[0m\n",
      "│\n",
      "│\n",
      "│    Evaluating candidate prompt 2:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  Given the {context}, provide a clear and concise answer to the    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  {question}. Ensure the answer is directly supported by the        \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  context and highlights the main objectives or themes discussed.   \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7bfbf847a441babb2c3a44aac41f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m│          Evaluation score: 0.8000 (-3.45%)\u001b[0m\n",
      "│\n",
      "│\n",
      "│    Evaluating candidate prompt 3:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  Based on the {context}, answer the {question} by summarizing the  \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  key points related to the question. Your answer should be         \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  concise and directly tied to the context provided.                \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddd54156d924dfea2f576423a2c761b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m│          Evaluation score: 0.7714 (-6.90%)\u001b[0m\n",
      "│\n",
      "│\n",
      "│    Completed optimization round 1 of 3\n",
      "\u001b[32m│    Found a new best performing prompt: 0.9143 (10.34%)\u001b[0m\n",
      "│\n",
      "│ - Starting optimization round 2 of 3\n",
      "│    Generating candidate prompts:\n",
      "\u001b[2m│      Successfully generated 3 candidate prompts\u001b[0m\n",
      "│\n",
      "│    Evaluating candidate prompt 1:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  Using the provided {context}, answer the {question} by            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  identifying the main goal or key information. Ensure your         \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  response is concise, directly related to the question, and        \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  supported by the context.                                         \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6847c15ef9e1487ebae03b14c8a73f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m│          Evaluation score: 0.8286 (-9.38%)\u001b[0m\n",
      "│\n",
      "│\n",
      "│    Evaluating candidate prompt 2:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  Refer to the provided {context} to accurately answer the          \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  {question}. Focus on extracting the main objectives or themes,    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  ensuring your response is concise and directly tied to the        \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  context.                                                          \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff6a8226e8e4cb0bbccd6f4156e54b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from opik_optimizer import TaskConfig\n",
    "\n",
    "results = []\n",
    "\n",
    "for optim in optims:\n",
    "    print(f\"Optimizing using {optim.__class__.__name__}\")\n",
    "    # MIPRO is bugged\n",
    "    # if isinstance(optim, MiproOptimizer):\n",
    "    #     res = optim.optimize_prompt(\n",
    "    #         dataset=dataset,\n",
    "    #         metric=fi_eval,\n",
    "    #         task_config = TaskConfig(\n",
    "    #             instruction_prompt = common_opt_run_params['prompt'].user,\n",
    "    #             input_dataset_fields = ['question','context'],\n",
    "    #             output_dataset_field = 'answer',\n",
    "    #             use_chat_prompt = True\n",
    "    #         ),\n",
    "    #         num_candidates=1,\n",
    "    #     )\n",
    "    # else:\n",
    "    res = optim.optimize_prompt(\n",
    "        **common_opt_run_params\n",
    "    )\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb7bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m╔═\u001b[0m\u001b[33m════════════════════════════════════════════\u001b[0m\u001b[33m \u001b[0m\u001b[1;33mOptimization Complete\u001b[0m\u001b[33m \u001b[0m\u001b[33m════════════════════════════════════════════\u001b[0m\u001b[33m═╗\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mOptimizer:            \u001b[0m\u001b[2m \u001b[0m\u001b[1mMetaPromptOptimizer\u001b[0m                                                                      \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mModel Used:           \u001b[0m\u001b[2m \u001b[0mopenai/gpt-4o-mini                                                                       \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mMetric Evaluated:     \u001b[0m\u001b[2m \u001b[0m\u001b[1mcosine_score\u001b[0m                                                                             \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mInitial Score:        \u001b[0m\u001b[2m \u001b[0m0.7537                                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mFinal Best Score:     \u001b[0m\u001b[2m \u001b[0m\u001b[1;36m0.8593\u001b[0m                                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mTotal Improvement:    \u001b[0m\u001b[2m \u001b[0m\u001b[1;32m14.01%\u001b[0m                                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mRounds Completed:     \u001b[0m\u001b[2m \u001b[0m3                                                                                        \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mOptimization run link:\u001b[0m\u001b[2m \u001b[0m\u001b]8;id=107473;https://www.comet.com/opik/api/v1/session/redirect/optimizations/?optimization_id=019976c6-b011-7c1a-b9b3-1184fa1fd1f3&dataset_id=01997609-de6f-707e-ba5c-3c7756e0eb62&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\u001b\\Open in Opik Dashboard\u001b]8;;\u001b\\                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mFinal Optimized Prompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m──────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m                                                                                                             \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  \u001b[1;35mSystem:\u001b[0m Use the provided {context} to answer the {question} accurately. Your response should be concise,   \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  directly address the question, and be based solely on the information within the context.                  \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  ---                                                                                                        \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  \u001b[1;32mUser:\u001b[0m given {context}, answer the {question}                                                               \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  ---                                                                                                        \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m                                                                                                             \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m╚═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "Optimization run link: https://www.comet.com/opik/api/v1/session/redirect/optimizations/?optimization_id=019976c6-b011-7c1a-b9b3-1184fa1fd1f3&dataset_id=01997609-de6f-707e-ba5c-3c7756e0eb62&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\n",
      "\u001b[33m╔═\u001b[0m\u001b[33m════════════════════════════════════════════\u001b[0m\u001b[33m \u001b[0m\u001b[1;33mOptimization Complete\u001b[0m\u001b[33m \u001b[0m\u001b[33m════════════════════════════════════════════\u001b[0m\u001b[33m═╗\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mOptimizer:            \u001b[0m\u001b[2m \u001b[0m\u001b[1mEvolutionaryOptimizer\u001b[0m                                                                    \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mModel Used:           \u001b[0m\u001b[2m \u001b[0mopenai/gpt-4o-mini                                                                       \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mMetric Evaluated:     \u001b[0m\u001b[2m \u001b[0m\u001b[1mcosine_score\u001b[0m                                                                             \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mInitial Score:        \u001b[0m\u001b[2m \u001b[0m0.7537                                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mFinal Best Score:     \u001b[0m\u001b[2m \u001b[0m\u001b[1;36m0.7537\u001b[0m                                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mTotal Improvement:    \u001b[0m\u001b[2m \u001b[0m0.00%                                                                                    \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mRounds Completed:     \u001b[0m\u001b[2m \u001b[0m3                                                                                        \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mOptimization run link:\u001b[0m\u001b[2m \u001b[0m\u001b]8;id=776646;https://www.comet.com/opik/api/v1/session/redirect/optimizations/?optimization_id=019976c7-ab9c-7f45-8954-258b1b1c7679&dataset_id=01997609-de6f-707e-ba5c-3c7756e0eb62&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\u001b\\Open in Opik Dashboard\u001b]8;;\u001b\\                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mFinal Optimized Prompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m──────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m                                                                                                             \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  \u001b[1;32mUser:\u001b[0m given {context}, answer the {question}                                                               \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  ---                                                                                                        \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m                                                                                                             \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m╚═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "Optimization run link: https://www.comet.com/opik/api/v1/session/redirect/optimizations/?optimization_id=019976c7-ab9c-7f45-8954-258b1b1c7679&dataset_id=01997609-de6f-707e-ba5c-3c7756e0eb62&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\n",
      "\u001b[33m╔═\u001b[0m\u001b[33m════════════════════════════════════════════\u001b[0m\u001b[33m \u001b[0m\u001b[1;33mOptimization Complete\u001b[0m\u001b[33m \u001b[0m\u001b[33m════════════════════════════════════════════\u001b[0m\u001b[33m═╗\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mOptimizer:            \u001b[0m\u001b[2m \u001b[0m\u001b[1mFewShotBayesianOptimizer\u001b[0m                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mModel Used:           \u001b[0m\u001b[2m \u001b[0mopenai/gpt-4o-mini                                                                       \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mMetric Evaluated:     \u001b[0m\u001b[2m \u001b[0m\u001b[1mcosine_score\u001b[0m                                                                             \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mInitial Score:        \u001b[0m\u001b[2m \u001b[0m0.7204                                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mFinal Best Score:     \u001b[0m\u001b[2m \u001b[0m\u001b[1;36m0.7204\u001b[0m                                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mTotal Improvement:    \u001b[0m\u001b[2m \u001b[0m0.00%                                                                                    \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mRounds Completed:     \u001b[0m\u001b[2m \u001b[0m0                                                                                        \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mOptimization run link:\u001b[0m\u001b[2m \u001b[0m\u001b]8;id=571858;https://www.comet.com/opik/api/v1/session/redirect/optimizations/?optimization_id=019976c8-e646-7edf-8428-53a004050470&dataset_id=01997609-de6f-707e-ba5c-3c7756e0eb62&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\u001b\\Open in Opik Dashboard\u001b]8;;\u001b\\                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mFinal Optimized Prompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m──────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m                                                                                                             \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  \u001b[1;32mUser:\u001b[0m given {context}, answer the {question}                                                               \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  ---                                                                                                        \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m                                                                                                             \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m╚═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "Optimization run link: https://www.comet.com/opik/api/v1/session/redirect/optimizations/?optimization_id=019976c8-e646-7edf-8428-53a004050470&dataset_id=01997609-de6f-707e-ba5c-3c7756e0eb62&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\n"
     ]
    }
   ],
   "source": [
    "for res in results:\n",
    "    res.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b05504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-opts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

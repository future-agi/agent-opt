{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "045051a3",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4469805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opik.evaluation.metrics.score_result import ScoreResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2f8cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in our code bleu score is actually cosine similarity which uses this class and function I GUESS\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import re, math\n",
    "class Comparator(ABC):\n",
    "    @abstractmethod\n",
    "    def compare(self, string1, string2):\n",
    "        pass\n",
    "\n",
    "class CosineSimilarity(Comparator):\n",
    "    def compare(self, string1, string2):\n",
    "        # Tokenize and create a combined set of unique words\n",
    "        combined_set = self._create_combined_set(string1, string2)\n",
    "        # Vectorize the strings\n",
    "        vector1 = self._vectorize(string1, combined_set)\n",
    "        vector2 = self._vectorize(string2, combined_set)\n",
    "        dot_product = sum(p*q for p, q in zip(vector1, vector2))\n",
    "        magnitude_vec1 = math.sqrt(sum([val**2 for val in vector1]))\n",
    "        magnitude_vec2 = math.sqrt(sum([val**2 for val in vector2]))\n",
    "        if magnitude_vec1 * magnitude_vec2 == 0:\n",
    "            # Avoid division by zero\n",
    "            return 0\n",
    "        return dot_product / (magnitude_vec1 * magnitude_vec2)\n",
    "\n",
    "    def _tokenize(self, string):\n",
    "        \"\"\"\n",
    "        Tokenize the input string into a list of words.\n",
    "        \n",
    "        Args:\n",
    "            string (str): The string to tokenize.\n",
    "        \n",
    "        Returns:\n",
    "            list: A list of lowercased words from the string.\n",
    "        \"\"\"\n",
    "        return re.findall(r'\\b\\w+\\b', string.lower())\n",
    "\n",
    "    def _create_combined_set(self, string1, string2):\n",
    "        return set(self._tokenize(string1)).union(set(self._tokenize(string2)))\n",
    "\n",
    "    def _vectorize(self, string, combined_set):\n",
    "        tokenized = self._tokenize(string)\n",
    "        vector = [tokenized.count(word) for word in combined_set]\n",
    "        return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "727150ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opik expects the SAME keywords for the metric function else it throws an unknown error that doesnt even tell u the problem is with keywords. \n",
    "def cosine_score(dataset_item, llm_output):\n",
    "    score = CosineSimilarity().compare(dataset_item.get('answer'), llm_output)\n",
    "    return ScoreResult(name=\"CosineSimilarity\", value=score, reason=f\"Cosine similarity was found to be {score}\", scoring_failed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c696bfdc",
   "metadata": {},
   "source": [
    "## FutureAGI Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2305c64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/Desktop/agent-opts/.venv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:198: UserWarning: Field name \"json\" in \"RequestConfig\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from fi.evals import Evaluator\n",
    "evaluator = Evaluator()\n",
    "\n",
    "def fi_eval(dataset_item, llm_output):\n",
    "    eval = evaluator.evaluate(\n",
    "        eval_templates=\"context_adherence\",\n",
    "        model_name=\"turing_flash\",\n",
    "        inputs={\n",
    "            \"context\": dataset_item.get(\"context\"),\n",
    "            \"output\": llm_output\n",
    "        }\n",
    "    )\n",
    "    return ScoreResult(name=\"FutureAGI Eval\", value=eval.eval_results[0].output, reason=eval.eval_results[0].reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c34eaffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdc274a",
   "metadata": {},
   "source": [
    "## Create Dataset and Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b55b32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opik_optimizer import ChatPrompt\n",
    "from opik import Opik\n",
    "import pandas as pd\n",
    "\n",
    "# generated answer is the column which uses the prompt 'given {{context}}, answer the {{question}}' \n",
    "# answer similarity uses bleu score betweeen generated answer and the answer\n",
    "data = pd.read_csv('demo-dataset.csv')[['context','question','answer','generated answer', 'Answer Similarity', 'Groundedness']]\n",
    "\n",
    "cli= Opik(project_name='fi')\n",
    "\n",
    "dataset = cli.get_or_create_dataset(name='prompt-opt-test')\n",
    "dataset.insert_from_pandas(dataframe=data)\n",
    "\n",
    "initial_prompt = ChatPrompt(\n",
    "    name = 'init-qa-prompt',\n",
    "    user='given {context}, answer the {question}',\n",
    "    project_name=\"fi\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c55fc19",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "098fee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opik_optimizer import MetaPromptOptimizer, EvolutionaryOptimizer, FewShotBayesianOptimizer\n",
    "from opik_optimizer.mipro_optimizer import MiproOptimizer\n",
    "\n",
    "common_opt_params = {\n",
    "    \"model\":'openai/gpt-4o-mini',\n",
    "    \"temperature\":0.5,\n",
    "    \"verbose\":1,\n",
    "    \"n_threads\":5,\n",
    "    \"max_tokens\":1024,\n",
    "    # \"seed\":47\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abd0d9c",
   "metadata": {},
   "source": [
    "## Meta Prompt Optimizer\n",
    "mainly used for re-wording the prompt, and not really recommended for complex tasks like agentic or prompts with few shot examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d93a1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_optimizer = MetaPromptOptimizer(\n",
    "    **common_opt_params,\n",
    "    reasoning_model='openai/gpt-4o',\n",
    "    max_rounds = 3,\n",
    "    num_prompts_per_round=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8feeb7",
   "metadata": {},
   "source": [
    "## Evolutionary Optimizer\n",
    "main usecase is optimizing for complex evaluations, or group of evaluations. It uses much higher number of mutations to explore as many prompt combinations as possible.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f84230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evo_optimizer = EvolutionaryOptimizer(\n",
    "    **common_opt_params,\n",
    "    population_size=3,                 # Number of prompts in each generation\n",
    "    num_generations=2,                 # Number of iterations the algorithm will run\n",
    "    mutation_rate=0.2,                  # Probability of mutating an individual\n",
    "    crossover_rate=0.8,                 # Probability of crossing over two individuals\n",
    "    tournament_size=4,                  # Size of the tournament for selection (if not MOO)\n",
    "    elitism_size=3,                     # Number of best individuals to carry over (if not MOO)\n",
    "    adaptive_mutation=True,\n",
    "    enable_llm_crossover=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2a85c8",
   "metadata": {},
   "source": [
    "## FewShot Bayesian Optimizer\n",
    "used when prompts should contain fewshot examples. can burn through tokens very easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbb86328",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_optimizer = FewShotBayesianOptimizer(\n",
    "    **common_opt_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f0d0f",
   "metadata": {},
   "source": [
    "## MIPRO Optimizer\n",
    "main use case is complex multi step reasoning or tool use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b50d8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "mipro_optimizer = MiproOptimizer(\n",
    "    model = common_opt_params['model'],\n",
    "    project_name=\"fi\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ab98c",
   "metadata": {},
   "source": [
    "## Final Optimize Prompt Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f693165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_opt_run_params = {\n",
    "    \"prompt\": initial_prompt,\n",
    "    \"dataset\": dataset,\n",
    "    \"metric\": fi_eval,\n",
    "    \"n_samples\": 7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84d41759",
   "metadata": {},
   "outputs": [],
   "source": [
    "optims = [meta_optimizer, evo_optimizer, bayes_optimizer]\n",
    "# evo takes much much much longer to optimize. Really not recommended tbh. Should run separately.\n",
    "# bayes results in hallucinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "989f51ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing using MetaPromptOptimizer\n",
      "╭────────────────────────────────────────────────────────────────────╮\n",
      "│ \u001b[32m● \u001b[0mRunning Opik Evaluation - \u001b[34mMetaPromptOptimizer\u001b[0m                    │\n",
      "│                                                                    │\n",
      "│ -> View optimization details \u001b]8;id=26225;https://www.comet.com/opik/api/v1/session/redirect/optimizations/?optimization_id=019976db-87ce-7da4-815a-2d92dd071486&dataset_id=01997609-de6f-707e-ba5c-3c7756e0eb62&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\u001b\\in your Opik dashboard\u001b]8;;\u001b\\                │\n",
      "╰────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "\n",
      "> Let's optimize the prompt:\n",
      "\n",
      "\u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\n",
      "Using MetaPromptOptimizer with the parameters: \n",
      "\u001b[2m  - n_samples: \u001b[0m\u001b[36m7\u001b[0m\n",
      "\u001b[2m  - auto_continue: \u001b[0m\u001b[36mFalse\u001b[0m\n",
      "\n",
      "\n",
      "> First we will establish the baseline performance:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03b356b85cc463794d2cf29e7c8eeae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m  Baseline score was: 0.8286.\u001b[0m\n",
      "\n",
      "> Starting the optimization run\n",
      "│\n",
      "│ - Starting optimization round 1 of 3\n",
      "│    Generating candidate prompts:\n",
      "\u001b[2m│      Successfully generated 3 candidate prompts\u001b[0m\n",
      "│\n",
      "│    Evaluating candidate prompt 1:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  Using the provided {context}, accurately answer the {question}    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  by focusing on the main goal or key information. Ensure your      \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  response is concise and directly related to the question.         \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1430e8b06a5943b8981700b4034e3a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m│          Evaluation score: 0.9143 (10.34%)\u001b[0m\n",
      "│\n",
      "│\n",
      "│    Evaluating candidate prompt 2:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  Given the {context}, provide a clear and concise answer to the    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  {question}. Ensure the answer is directly supported by the        \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  context and highlights the main objectives or themes discussed.   \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7bfbf847a441babb2c3a44aac41f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m│          Evaluation score: 0.8000 (-3.45%)\u001b[0m\n",
      "│\n",
      "│\n",
      "│    Evaluating candidate prompt 3:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  Based on the {context}, answer the {question} by summarizing the  \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  key points related to the question. Your answer should be         \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  concise and directly tied to the context provided.                \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddd54156d924dfea2f576423a2c761b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m│          Evaluation score: 0.7714 (-6.90%)\u001b[0m\n",
      "│\n",
      "│\n",
      "│    Completed optimization round 1 of 3\n",
      "\u001b[32m│    Found a new best performing prompt: 0.9143 (10.34%)\u001b[0m\n",
      "│\n",
      "│ - Starting optimization round 2 of 3\n",
      "│    Generating candidate prompts:\n",
      "\u001b[2m│      Successfully generated 3 candidate prompts\u001b[0m\n",
      "│\n",
      "│    Evaluating candidate prompt 1:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  Using the provided {context}, answer the {question} by            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  identifying the main goal or key information. Ensure your         \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  response is concise, directly related to the question, and        \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  supported by the context.                                         \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6847c15ef9e1487ebae03b14c8a73f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m│          Evaluation score: 0.8286 (-9.38%)\u001b[0m\n",
      "│\n",
      "│\n",
      "│    Evaluating candidate prompt 2:\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m system \u001b[0m\u001b[2m──────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  Refer to the provided {context} to accurately answer the          \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  {question}. Focus on extracting the main objectives or themes,    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  ensuring your response is concise and directly tied to the        \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  context.                                                          \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "│         \u001b[2m╭─\u001b[0m\u001b[2m user \u001b[0m\u001b[2m────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m  given {context}, answer the {question}                            \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m│\u001b[0m                                                                    \u001b[2m│\u001b[0m\n",
      "│         \u001b[2m╰────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff6a8226e8e4cb0bbccd6f4156e54b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOptimizing using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptim.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# MIPRO is bugged\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# if isinstance(optim, MiproOptimizer):\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#     res = optim.optimize_prompt(\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m res = \u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcommon_opt_run_params\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m results.append(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/agent-opts/.venv/lib/python3.11/site-packages/opik_optimizer/meta_prompt_optimizer/meta_prompt_optimizer.py:431\u001b[39m, in \u001b[36mMetaPromptOptimizer.optimize_prompt\u001b[39m\u001b[34m(self, prompt, dataset, metric, experiment_config, n_samples, auto_continue, agent_class, **kwargs)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    430\u001b[39m     optimization_id = optimization.id \u001b[38;5;28;01mif\u001b[39;00m optimization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimize_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimization_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimization_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauto_continue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauto_continue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m optimization:\n\u001b[32m    442\u001b[39m         \u001b[38;5;28mself\u001b[39m.update_optimization(optimization, status=\u001b[33m\"\u001b[39m\u001b[33mcompleted\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/agent-opts/.venv/lib/python3.11/site-packages/opik_optimizer/meta_prompt_optimizer/meta_prompt_optimizer.py:539\u001b[39m, in \u001b[36mMetaPromptOptimizer._optimize_prompt\u001b[39m\u001b[34m(self, optimization_id, prompt, dataset, metric, experiment_config, n_samples, auto_continue, **kwargs)\u001b[39m\n\u001b[32m    536\u001b[39m new_prompt.set_messages(prompt.get_messages())\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m     prompt_score = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimization_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimization_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_full_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    550\u001b[39m     eval_report.set_final_score(best_score, prompt_score)\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/agent-opts/.venv/lib/python3.11/site-packages/opik_optimizer/meta_prompt_optimizer/meta_prompt_optimizer.py:331\u001b[39m, in \u001b[36mMetaPromptOptimizer._evaluate_prompt\u001b[39m\u001b[34m(self, prompt, dataset, metric, n_samples, dataset_item_ids, experiment_config, use_full_dataset, optimization_id, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;66;03m# Use dataset's get_items with limit for sampling\u001b[39;00m\n\u001b[32m    328\u001b[39m logger.debug(\n\u001b[32m    329\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting evaluation with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubset_size\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39msubset_size\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mall\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m samples for metric: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(metric,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m__name__\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mstr\u001b[39m(metric))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    330\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m score = \u001b[43mtask_evaluator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluated_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_item_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_item_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use subset_size for trials, None for full dataset\u001b[39;49;00m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimization_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimization_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    343\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEvaluation score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/agent-opts/.venv/lib/python3.11/site-packages/opik_optimizer/task_evaluator.py:81\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(dataset, evaluated_task, metric, num_threads, optimization_id, dataset_item_ids, project_name, n_samples, experiment_config, verbose)\u001b[39m\n\u001b[32m     78\u001b[39m eval_metrics = [_create_metric_class(metric)]\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m optimization_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     result = \u001b[43mopik_evaluator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_optimization_trial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimization_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimization_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluated_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_item_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_item_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscoring_metrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnb_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     94\u001b[39m     result = opik_evaluator.evaluate(\n\u001b[32m     95\u001b[39m         dataset=dataset,\n\u001b[32m     96\u001b[39m         task=evaluated_task,\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m         verbose=verbose,\n\u001b[32m    104\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/agent-opts/.venv/lib/python3.11/site-packages/opik/evaluation/evaluator.py:525\u001b[39m, in \u001b[36mevaluate_optimization_trial\u001b[39m\u001b[34m(optimization_id, dataset, task, scoring_metrics, experiment_name, project_name, experiment_config, verbose, nb_samples, task_threads, prompt, prompts, scoring_key_mapping, dataset_item_ids, dataset_sampler, trial_count)\u001b[39m\n\u001b[32m    514\u001b[39m client = opik_client.get_client_cached()\n\u001b[32m    516\u001b[39m experiment = client.create_experiment(\n\u001b[32m    517\u001b[39m     name=experiment_name,\n\u001b[32m    518\u001b[39m     dataset_name=dataset.name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    522\u001b[39m     optimization_id=optimization_id,\n\u001b[32m    523\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring_metrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscoring_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnb_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnb_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring_key_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscoring_key_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_item_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_item_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_sampler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrial_count\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/agent-opts/.venv/lib/python3.11/site-packages/opik/evaluation/evaluator.py:154\u001b[39m, in \u001b[36m_evaluate_task\u001b[39m\u001b[34m(client, experiment, dataset, task, scoring_metrics, project_name, verbose, nb_samples, task_threads, scoring_key_mapping, dataset_item_ids, dataset_sampler, trial_count)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m asyncio_support.async_http_connections_expire_immediately():\n\u001b[32m    145\u001b[39m     evaluation_engine = engine.EvaluationEngine(\n\u001b[32m    146\u001b[39m         client=client,\n\u001b[32m    147\u001b[39m         project_name=project_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    152\u001b[39m         scoring_key_mapping=scoring_key_mapping,\n\u001b[32m    153\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     test_results = \u001b[43mevaluation_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_llm_tasks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnb_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnb_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_item_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_item_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_sampler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial_count\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m total_time = time.time() - start_time\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/agent-opts/.venv/lib/python3.11/site-packages/opik/evaluation/engine/engine.py:193\u001b[39m, in \u001b[36mEvaluationEngine.evaluate_llm_tasks\u001b[39m\u001b[34m(self, dataset_, task, nb_samples, dataset_item_ids, dataset_sampler, trial_count)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m trial_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(trial_count):\n\u001b[32m    183\u001b[39m     evaluation_tasks: List[EvaluationTask[test_result.TestResult]] = [\n\u001b[32m    184\u001b[39m         functools.partial(\n\u001b[32m    185\u001b[39m             \u001b[38;5;28mself\u001b[39m._evaluate_llm_task,\n\u001b[32m   (...)\u001b[39m\u001b[32m    190\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m dataset_items\n\u001b[32m    191\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     test_results += \u001b[43mevaluation_tasks_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluation_tasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvaluation trial \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtrial_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial_count\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvaluation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m test_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/agent-opts/.venv/lib/python3.11/site-packages/opik/evaluation/engine/evaluation_tasks_executor.py:36\u001b[39m, in \u001b[36mexecute\u001b[39m\u001b[34m(evaluation_tasks, workers, verbose, desc)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m futures.ThreadPoolExecutor(max_workers=workers) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m     32\u001b[39m     test_result_futures = [\n\u001b[32m     33\u001b[39m         pool.submit(evaluation_task) \u001b[38;5;28;01mfor\u001b[39;00m evaluation_task \u001b[38;5;129;01min\u001b[39;00m evaluation_tasks\n\u001b[32m     34\u001b[39m     ]\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     test_results = \u001b[43m[\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest_result_future\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_result_future\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_tqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtest_result_futures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_result_futures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m test_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/agent-opts/.venv/lib/python3.11/site-packages/opik/evaluation/engine/evaluation_tasks_executor.py:36\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m futures.ThreadPoolExecutor(max_workers=workers) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m     32\u001b[39m     test_result_futures = [\n\u001b[32m     33\u001b[39m         pool.submit(evaluation_task) \u001b[38;5;28;01mfor\u001b[39;00m evaluation_task \u001b[38;5;129;01min\u001b[39;00m evaluation_tasks\n\u001b[32m     34\u001b[39m     ]\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     test_results = \u001b[43m[\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest_result_future\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_result_future\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_tqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtest_result_futures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_result_futures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m test_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/agent-opts/.venv/lib/python3.11/site-packages/rich/progress.py:173\u001b[39m, in \u001b[36mtrack\u001b[39m\u001b[34m(sequence, description, total, completed, auto_refresh, console, transient, get_time, refresh_per_second, style, complete_style, finished_style, pulse_style, update_period, disable, show_speed)\u001b[39m\n\u001b[32m    162\u001b[39m progress = Progress(\n\u001b[32m    163\u001b[39m     *columns,\n\u001b[32m    164\u001b[39m     auto_refresh=auto_refresh,\n\u001b[32m   (...)\u001b[39m\u001b[32m    169\u001b[39m     disable=disable,\n\u001b[32m    170\u001b[39m )\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m progress:\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m progress.track(\n\u001b[32m    174\u001b[39m         sequence,\n\u001b[32m    175\u001b[39m         total=total,\n\u001b[32m    176\u001b[39m         completed=completed,\n\u001b[32m    177\u001b[39m         description=description,\n\u001b[32m    178\u001b[39m         update_period=update_period,\n\u001b[32m    179\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/agent-opts/.venv/lib/python3.11/site-packages/rich/progress.py:1225\u001b[39m, in \u001b[36mProgress.track\u001b[39m\u001b[34m(self, sequence, total, completed, task_id, description, update_period)\u001b[39m\n\u001b[32m   1223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.live.auto_refresh:\n\u001b[32m   1224\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _TrackThread(\u001b[38;5;28mself\u001b[39m, task_id, update_period) \u001b[38;5;28;01mas\u001b[39;00m track_thread:\n\u001b[32m-> \u001b[39m\u001b[32m1225\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msequence\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrack_thread\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompleted\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.13-macos-aarch64-none/lib/python3.11/concurrent/futures/_base.py:243\u001b[39m, in \u001b[36mas_completed\u001b[39m\u001b[34m(fs, timeout)\u001b[39m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m wait_timeout < \u001b[32m0\u001b[39m:\n\u001b[32m    239\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[32m    240\u001b[39m                 \u001b[33m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m) futures unfinished\u001b[39m\u001b[33m'\u001b[39m % (\n\u001b[32m    241\u001b[39m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m waiter.lock:\n\u001b[32m    246\u001b[39m     finished = waiter.finished_futures\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.13-macos-aarch64-none/lib/python3.11/threading.py:629\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    627\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.13-macos-aarch64-none/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from opik_optimizer import TaskConfig\n",
    "\n",
    "results = []\n",
    "\n",
    "for optim in optims:\n",
    "    print(f\"Optimizing using {optim.__class__.__name__}\")\n",
    "    # MIPRO is bugged\n",
    "    # if isinstance(optim, MiproOptimizer):\n",
    "    #     res = optim.optimize_prompt(\n",
    "    #         dataset=dataset,\n",
    "    #         metric=fi_eval,\n",
    "    #         task_config = TaskConfig(\n",
    "    #             instruction_prompt = common_opt_run_params['prompt'].user,\n",
    "    #             input_dataset_fields = ['question','context'],\n",
    "    #             output_dataset_field = 'answer',\n",
    "    #             use_chat_prompt = True\n",
    "    #         ),\n",
    "    #         num_candidates=1,\n",
    "    #     )\n",
    "    # else:\n",
    "    res = optim.optimize_prompt(\n",
    "        **common_opt_run_params\n",
    "    )\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb7bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m╔═\u001b[0m\u001b[33m════════════════════════════════════════════\u001b[0m\u001b[33m \u001b[0m\u001b[1;33mOptimization Complete\u001b[0m\u001b[33m \u001b[0m\u001b[33m════════════════════════════════════════════\u001b[0m\u001b[33m═╗\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mOptimizer:            \u001b[0m\u001b[2m \u001b[0m\u001b[1mMetaPromptOptimizer\u001b[0m                                                                      \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mModel Used:           \u001b[0m\u001b[2m \u001b[0mopenai/gpt-4o-mini                                                                       \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mMetric Evaluated:     \u001b[0m\u001b[2m \u001b[0m\u001b[1mcosine_score\u001b[0m                                                                             \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mInitial Score:        \u001b[0m\u001b[2m \u001b[0m0.7537                                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mFinal Best Score:     \u001b[0m\u001b[2m \u001b[0m\u001b[1;36m0.8593\u001b[0m                                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mTotal Improvement:    \u001b[0m\u001b[2m \u001b[0m\u001b[1;32m14.01%\u001b[0m                                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mRounds Completed:     \u001b[0m\u001b[2m \u001b[0m3                                                                                        \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mOptimization run link:\u001b[0m\u001b[2m \u001b[0m\u001b]8;id=107473;https://www.comet.com/opik/api/v1/session/redirect/optimizations/?optimization_id=019976c6-b011-7c1a-b9b3-1184fa1fd1f3&dataset_id=01997609-de6f-707e-ba5c-3c7756e0eb62&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\u001b\\Open in Opik Dashboard\u001b]8;;\u001b\\                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mFinal Optimized Prompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m──────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m                                                                                                             \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  \u001b[1;35mSystem:\u001b[0m Use the provided {context} to answer the {question} accurately. Your response should be concise,   \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  directly address the question, and be based solely on the information within the context.                  \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  ---                                                                                                        \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  \u001b[1;32mUser:\u001b[0m given {context}, answer the {question}                                                               \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  ---                                                                                                        \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m                                                                                                             \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m╚═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "Optimization run link: https://www.comet.com/opik/api/v1/session/redirect/optimizations/?optimization_id=019976c6-b011-7c1a-b9b3-1184fa1fd1f3&dataset_id=01997609-de6f-707e-ba5c-3c7756e0eb62&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\n",
      "\u001b[33m╔═\u001b[0m\u001b[33m════════════════════════════════════════════\u001b[0m\u001b[33m \u001b[0m\u001b[1;33mOptimization Complete\u001b[0m\u001b[33m \u001b[0m\u001b[33m════════════════════════════════════════════\u001b[0m\u001b[33m═╗\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mOptimizer:            \u001b[0m\u001b[2m \u001b[0m\u001b[1mEvolutionaryOptimizer\u001b[0m                                                                    \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mModel Used:           \u001b[0m\u001b[2m \u001b[0mopenai/gpt-4o-mini                                                                       \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mMetric Evaluated:     \u001b[0m\u001b[2m \u001b[0m\u001b[1mcosine_score\u001b[0m                                                                             \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mInitial Score:        \u001b[0m\u001b[2m \u001b[0m0.7537                                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mFinal Best Score:     \u001b[0m\u001b[2m \u001b[0m\u001b[1;36m0.7537\u001b[0m                                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mTotal Improvement:    \u001b[0m\u001b[2m \u001b[0m0.00%                                                                                    \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mRounds Completed:     \u001b[0m\u001b[2m \u001b[0m3                                                                                        \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mOptimization run link:\u001b[0m\u001b[2m \u001b[0m\u001b]8;id=776646;https://www.comet.com/opik/api/v1/session/redirect/optimizations/?optimization_id=019976c7-ab9c-7f45-8954-258b1b1c7679&dataset_id=01997609-de6f-707e-ba5c-3c7756e0eb62&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\u001b\\Open in Opik Dashboard\u001b]8;;\u001b\\                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mFinal Optimized Prompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m──────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m                                                                                                             \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  \u001b[1;32mUser:\u001b[0m given {context}, answer the {question}                                                               \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  ---                                                                                                        \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m                                                                                                             \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m╚═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "Optimization run link: https://www.comet.com/opik/api/v1/session/redirect/optimizations/?optimization_id=019976c7-ab9c-7f45-8954-258b1b1c7679&dataset_id=01997609-de6f-707e-ba5c-3c7756e0eb62&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\n",
      "\u001b[33m╔═\u001b[0m\u001b[33m════════════════════════════════════════════\u001b[0m\u001b[33m \u001b[0m\u001b[1;33mOptimization Complete\u001b[0m\u001b[33m \u001b[0m\u001b[33m════════════════════════════════════════════\u001b[0m\u001b[33m═╗\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mOptimizer:            \u001b[0m\u001b[2m \u001b[0m\u001b[1mFewShotBayesianOptimizer\u001b[0m                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mModel Used:           \u001b[0m\u001b[2m \u001b[0mopenai/gpt-4o-mini                                                                       \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mMetric Evaluated:     \u001b[0m\u001b[2m \u001b[0m\u001b[1mcosine_score\u001b[0m                                                                             \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mInitial Score:        \u001b[0m\u001b[2m \u001b[0m0.7204                                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mFinal Best Score:     \u001b[0m\u001b[2m \u001b[0m\u001b[1;36m0.7204\u001b[0m                                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mTotal Improvement:    \u001b[0m\u001b[2m \u001b[0m0.00%                                                                                    \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mRounds Completed:     \u001b[0m\u001b[2m \u001b[0m0                                                                                        \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[2mOptimization run link:\u001b[0m\u001b[2m \u001b[0m\u001b]8;id=571858;https://www.comet.com/opik/api/v1/session/redirect/optimizations/?optimization_id=019976c8-e646-7edf-8428-53a004050470&dataset_id=01997609-de6f-707e-ba5c-3c7756e0eb62&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\u001b\\Open in Opik Dashboard\u001b]8;;\u001b\\                                                                   \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mFinal Optimized Prompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m──────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m                                                                                                             \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  \u001b[1;32mUser:\u001b[0m given {context}, answer the {question}                                                               \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m  ---                                                                                                        \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m│\u001b[0m                                                                                                             \u001b[34m│\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m \u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[33m║\u001b[0m\n",
      "\u001b[33m║\u001b[0m                                                                                                                 \u001b[33m║\u001b[0m\n",
      "\u001b[33m╚═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\u001b[0m\n",
      "Optimization run link: https://www.comet.com/opik/api/v1/session/redirect/optimizations/?optimization_id=019976c8-e646-7edf-8428-53a004050470&dataset_id=01997609-de6f-707e-ba5c-3c7756e0eb62&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\n"
     ]
    }
   ],
   "source": [
    "for res in results:\n",
    "    res.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b05504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-opts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
